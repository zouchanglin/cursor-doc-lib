大模型代理服务使用指南，务必采用兼容模式调用

## 1. 概述

本文档介绍如何使用大模型代理服务，该服务提供了与OpenAI兼容的使用方式。如果您之前使用OpenAI SDK、其他OpenAI兼容接口（如langchain_openai SDK）或HTTP方式调用OpenAI服务，只需调整少量参数即可使用本代理服务。

## 2. 兼容OpenAI所需信息

### 2.1 Base URL

根据您的使用环境，配置以下base_url：

- 测试环境：`http://[测试环境域名]/openai-compatible/v1`
- 生产环境：`http://[生产环境域名]/openai-compatible/v1`

使用HTTP访问时，完整URL为：

- 测试环境：`http://[测试环境域名]/openai-compatible/v1/chat/completions`
- 生产环境：`http://[生产环境域名]/openai-compatible/v1/chat/completions`

### 2.2 API Key

API Key由您在算力平台申请的应用的appID和appKey拼接组成，格式为：`appID:appKey`

例如：如果您的appID为1234，appKey为abc，则API Key为`1234:abc`

### 2.3 兼容情况

目前兼容`/chat/completions`接口。支持的厂商和模型请参考相关文档。

## 3. 通过OpenAI SDK调用

### 3.1 前提条件

1. 安装最新版OpenAI SDK
2. 已在模型广场申请应用
3. 选择支持的厂商模型

### 3.2 使用方式

#### 3.2.1 非流式调用

```python
from openai import OpenAI
import os

def get_response():
    client = OpenAI(
        api_key=os.getenv("TAL_MLOPS_APP_KEY"),  # 环境变量中的appid:appkey
        base_url="http://[测试环境域名]/openai-compatible/v1",  # 兼容服务的base_url
    )
    completion = client.chat.completions.create(
        model="gemini-1.5-pro",
        messages=[
            {'role': 'system', 'content': 'You are a helpful assistant.'},
            {'role': 'user', 'content': '你是谁？'}
        ]
    )
    print(completion.model_dump_json())

if __name__ == '__main__':
    get_response()
```

#### 3.2.2 流式调用

```python
from openai import OpenAI
import os

def get_response():
    client = OpenAI(
        api_key=os.getenv("TAL_MLOPS_APP_KEY"),  # 环境变量中的appid:appkey
        base_url="http://[测试环境域名]/openai-compatible/v1",  # 兼容服务的base_url
    )
    completion = client.chat.completions.create(
        model="gemini-1.5-pro",
        messages=[
            {'role': 'system', 'content': 'You are a helpful assistant.'},
            {'role': 'user', 'content': '你是谁？'}
        ],
        stream=True
    )
    for chunk in completion:
        print(chunk.model_dump_json())

if __name__ == '__main__':
    get_response()
```

## 4. 通过HTTP接口调用

### 4.1 前提条件

1. 已在模型广场申请应用
2. 选择支持的厂商模型

### 4.2 使用方式

参考OpenAI官方文档：https://platform.openai.com/docs/api-reference/chat/create

#### 4.2.1 非流式调用

```bash
curl --location 'http://[测试环境域名]/openai-compatible/v1/chat/completions' \
--header "Authorization: Bearer ${TAL_MLOPS_APP_ID}:${TAL_MLOPS_APP_KEY}" \
--header 'Content-Type: application/json' \
--data '{
    "model": "gemini-1.5-pro",
    "messages": [
        {
            "role": "system",
            "content": "You are a helpful assistant."
        },
        {
            "role": "user", 
            "content": "你是谁？"
        }
    ]
}'
```

#### 4.2.2 流式调用

```bash
curl --location 'http://[测试环境域名]/openai-compatible/v1/chat/completions' \
--header "Authorization: Bearer ${TAL_MLOPS_APP_ID}:${TAL_MLOPS_APP_KEY}" \
--header 'Content-Type: application/json' \
--data '{
    "model": "gemini-1.5-pro",
    "messages": [
        {
            "role": "system",
            "content": "You are a helpful assistant."
        },
        {
            "role": "user", 
            "content": "你是谁？"
        }
    ],
    "stream": true
}'
```

## 5. 注意事项

- 请确保使用正确的API Key和Base URL。
- 根据实际环境选择测试或生产环境的URL。
- 遵循相关的使用政策和限制。

## 6. 故障排除

如遇到问题，请检查：
1. API Key是否正确配置
2. Base URL是否正确
3. 是否选择了支持的模型
4. 网络连接是否正常

如问题持续，请联系技术支持。